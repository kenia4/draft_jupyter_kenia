{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beb83b23",
   "metadata": {},
   "source": [
    "# Tree regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81756b9",
   "metadata": {},
   "source": [
    "* Regression trees try to predict a continuous value, in contrast with classification trees thar classify people or things into two o more discrete categories. It is important to note that a regression tree is a tool focused beyond linear regressions and a regression tree its a type of decision tree.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ce7dc0",
   "metadata": {},
   "source": [
    " * The first step to build a regression trees is to identify that the plotting graphic of the data that we have in front have high level of variance, so using a regression line will not be very accurate in predicting. The second step for the construction of this tool would be to identify the base root, which is some continuous variable according to the groups that can be identified from the distribution of the data. The objective of build nods in regression trees is to make the information you have easier to understand, therefore, one of the final nodes must be the effect of meeting a series of conditions specified by the variables in the internal nodes. So, the third step would be to group identify, according to the graph, the ordered pairs that are most repeated, for this step it is important to keep in mind that the number of final nodes must be equal to the number of cuts that are made. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a735edb",
   "metadata": {},
   "source": [
    "* Those would be the basic steps when you have a single descriptive variable; however, if one were to have more than one descriptive variable, the goal is to minimize the next double summation, which is the sum of the residuals squared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc75bb4",
   "metadata": {},
   "source": [
    "$$ \\sum_{o = i}^{J}\\sum_{i \\epsilon  R_j} (Y_i - \\widehat{Y}_{Rj})^{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dc278d",
   "metadata": {},
   "source": [
    "* Where $ Y_i $ represents each entry of the endogenous variable of the data, $ \\widehat{Y}_{Rj} $ represents the same variable, but obtained from the regression tree and the $J$ indicates the number of groups, partitions or final nodes that were made and at the end the algorithm finds the regression tree that minimizes that sum."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
