{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79789d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting DoubleML\n",
      "  Downloading DoubleML-0.4.1-py3-none-any.whl (116 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\kenia\\anaconda3\\lib\\site-packages (from DoubleML) (1.7.1)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\kenia\\anaconda3\\lib\\site-packages (from DoubleML) (0.12.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\kenia\\anaconda3\\lib\\site-packages (from DoubleML) (1.3.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\kenia\\anaconda3\\lib\\site-packages (from DoubleML) (1.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kenia\\anaconda3\\lib\\site-packages (from DoubleML) (1.20.3)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\kenia\\anaconda3\\lib\\site-packages (from pandas->DoubleML) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\kenia\\anaconda3\\lib\\site-packages (from pandas->DoubleML) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kenia\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->DoubleML) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kenia\\anaconda3\\lib\\site-packages (from sklearn->DoubleML) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kenia\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->DoubleML) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5 in c:\\users\\kenia\\anaconda3\\lib\\site-packages (from statsmodels->DoubleML) (0.5.2)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1309 sha256=6c00057363e1c17d360bd936e904f419ca72abca540d03edfbb2f44110af3ee6\n",
      "  Stored in directory: c:\\users\\kenia\\appdata\\local\\pip\\cache\\wheels\\e4\\7b\\98\\b6466d71b8d738a0c547008b9eb39bf8676d1ff6ca4b22af1c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn, DoubleML\n",
      "Successfully installed DoubleML-0.4.1 sklearn-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U DoubleML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa868692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SyncRNG\n",
      "  Downloading SyncRNG-1.3.3-cp39-cp39-win_amd64.whl (19 kB)\n",
      "Installing collected packages: SyncRNG\n",
      "Successfully installed SyncRNG-1.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SyncRNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42dcfd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "from SyncRNG import SyncRNG\n",
    "import numpy as np\n",
    "import re\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "from scipy import linalg\n",
    "from itertools import chain\n",
    "\n",
    "from SyncRNG import SyncRNG\n",
    "\n",
    "from CTL.causal_tree_learn import CausalTree\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f01b36",
   "metadata": {},
   "source": [
    "# HTE I: Binary treatment\n",
    "\n",
    "Source RMD file: [link](https://docs.google.com/uc?export=download&id=1FSUi4WLfYYKnvWsNWypiQORhkqf5IlFP)\n",
    "\n",
    "In the previous chapter, we learned how to estimate the effect of a binary treatment averaged over the entire population. However, the average may obscure important details about how different individuals react to the treatment. In this chapter, we will learn how to estimate the **conditional average treatment effect (CATE)**,\n",
    "\\begin{equation}\n",
    "  (\\#eq:cate)\n",
    "  \\tau(x) := \\E[Y_i(1) - Y_i(0) | X_i = x],\n",
    "\\end{equation}\n",
    "which is a \"localized\" version of the average treatment effect conditional on a vector of observable characteristics. \n",
    "\n",
    "It's often the case that \\@ref(eq:cate) is too general to be immediately useful, especially when the observable covariates are high-dimensional. It can be hard to estimate reliably without making strong modeling assumptions, and hard to summarize in a useful manner after estimation. In such situations, we will instead try to estimate treatment effect averages for simpler groups\n",
    "\\begin{equation}\n",
    "  (\\#eq:cate-g)\n",
    "  \\E[Y_i(1) - Y_i(0) | G_i = g],\n",
    "\\end{equation}\n",
    "where $G_i$ indexes subgroups of interest. Below you'll learn how to estimate and test hypotheses about pre-defined subgroups, and also how to discover subgroups of interest from the data. In this tutorial, you will learn how to use estimates of \\@ref(eq:cate) to suggest relevant subgroups $G_i$ (and in the next chapters you will find out other uses of \\@ref(eq:cate) in policy learning and evaluation).\n",
    "\n",
    "We'll continue using the abridged version of the General Social Survey (GSS) [(Smith, 2016)](https://gss.norc.org/Documents/reports/project-reports/GSSProject%20report32.pdf) dataset that was introduced in the previous chapter. In this dataset, individuals were sent to treatment or control with equal probability, so we are in a randomized setting. However, many of the techniques and code shown below should also work in an observational setting provided that unconfoundedness and overlap are satisfied (these assumptions were defined in the previous chapter)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a981637",
   "metadata": {},
   "source": [
    "As with other chapters in this tutorial, the code below should still work by replacing the next snippet of code with a different dataset, provided that you update the key variables `treatment`, `outcome`, and `covariates` below. Also, please make sure to read the comments as they may be subtle differences depending on whether your dataset was created in a randomized or observational setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "48366a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv( \"https://docs.google.com/uc?id=1kSxrVci_EUcSr_Lg1JKk1l7Xd5I9zfRC&export=download\" )\n",
    "\n",
    "n = data.shape[0]\n",
    "\n",
    "# Treatment: does the the gov't spend too much on \"welfare\" (1) or \"assistance to the poor\" (0)\n",
    "treatment = \"w\"\n",
    "\n",
    "# Outcome: 1 for 'yes', 0 for 'no'\n",
    "outcome = \"y\"\n",
    "\n",
    "# Additional covariates\n",
    "covariates = [\"age\", \"polviews\", \"income\", \"educ\", \"marital\", \"sex\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bfb00e",
   "metadata": {},
   "source": [
    "## Pre-specified hypotheses\n",
    "\n",
    "We will begin by learning how to test pre-specified null hypotheses of the form\n",
    "\\begin{equation}\n",
    "  (\\#eq:hte-hyp)\n",
    "  H_{0}: \\E[Y(1) - Y(0) | G_i = 1] = \\E[Y(1) - Y(0) | G_i = 0].\n",
    "\\end{equation}\n",
    "\n",
    "That is, that the treatment effect is the same regardless of membership to some group\n",
    "$G_i$. Importantly, for now we’ll assume that the group $G_i$ was **pre-specified** -- it was decided _before_ looking at the data.\n",
    "\n",
    "In a randomized setting, if the both the treatment  $W_i$ and group membership $G_i$ are binary, we can write\n",
    "\\begin{equation}\n",
    "  (\\#eq:linear)\n",
    "  \\E[Y_i(W_i)|G_i] = \\E[Y_i|W_i, G_i] = \\beta_0 + \\beta_w W_i + \\beta_g G_i + \\beta_{wg} W_i G_i\n",
    "\\end{equation}\n",
    "\n",
    "<font size=1>\n",
    "When $W_i$ and $G_i$ are binary, this decomposition is true without loss of generality. Why?\n",
    "</font>\n",
    "\n",
    "This allows us to write the average effects of $W_i$ and $G_i$ on $Y_i$ as\n",
    "\\begin{equation}\n",
    "  (\\#eq:decomp)\n",
    "  \\begin{aligned}\n",
    "    \\E[Y(1) | G_i=1] &= \\beta_0 + \\beta_w W_i + \\beta_g G_i + \\beta_{wg} W_i G_i, \\\\\n",
    "    \\E[Y(1) | G_i=0] &= \\beta_0 + \\beta_w W_i,  \\\\\n",
    "    \\E[Y(0) | G_i=1] &= \\beta_0 + \\beta_g G_i,  \\\\\n",
    "    \\E[Y(0) | G_i=0] &= \\beta_0.\n",
    "  \\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "Rewriting the null hypothesis \\@ref(eq:hte-hyp) in terms of the decomposition \\@ref(eq:decomp), we see that it boils down to a test about the coefficient in the interaction: $\\beta_{xw} = 0$. Here’s an example that tests whether the treatment effect is the same for \"conservative\" (`polviews` < 4) and \"liberal\" (`polviews` $\\geq$ 4) individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "cb2fe372",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"conservative\"] = np.multiply(data.polviews < 4, 1)  # a binary group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "8c8ae044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Test for Constraints                               \n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept          0.4836      0.005     95.127      0.000       0.474       0.494\n",
      "w                 -0.3789      0.006    -64.657      0.000      -0.390      -0.367\n",
      "conservative      -0.1590      0.009    -17.195      0.000      -0.177      -0.141\n",
      "w:conservative     0.1160      0.010     11.185      0.000       0.096       0.136\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Only valid in randomized settings\n",
    "\n",
    "# Suppose this his group was defined prior to collecting the data\n",
    "data[\"conservative\"] = np.multiply(data.polviews < 4, 1)  # a binary group\n",
    "group = 'conservative'\n",
    "\n",
    "# Recall from last chapter -- this is equivalent to running a t-test\n",
    "fmla = 'y ~ w*conservative'\n",
    "ols = smf.ols(fmla, data=data).fit(cov_type='HC2')\n",
    "# print(ols_1.summary())\n",
    "hypotheses = 'Intercept=0, w=0, conservative=0, w:conservative=0'\n",
    "t_test = ols.t_test(hypotheses)\n",
    "print(t_test.summary(xname=list(ols.summary2().tables[1].index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688f14d9",
   "metadata": {},
   "source": [
    "<font size=1>\n",
    "Interpret the results above. The coefficient $\\beta_{xw}$ is denoted by `w:conservativeTRUE`. Can we detect a difference in treatment effect for conservative vs liberal individuals? For whom is the effect larger?\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e6320d",
   "metadata": {},
   "source": [
    "## Data-driven hypotheses\n",
    "\n",
    "Pre-specifying hypotheses prior to looking at the data is in general good practice to avoid \"p-hacking\" (e.g., slicing the data into different subgroups until a significant result is found). However, valid tests can also be attained if by **sample splitting**: we can use a subset of the sample to find promising subgroups, then test hypotheses about these subgroups in the remaining sample. This kind of sample splitting for hypothesis testing is called **honesty**.\n",
    "\n",
    "### Via causal trees\n",
    "\n",
    "**Causal trees** [(Athey and Imbens)](PNAS, 2016)](https://www.pnas.org/content/pnas/113/27/7353.full.pdf) are an intuitive algorithm that is available in the randomized setting to discover subgroups with different treatment effects.\n",
    "\n",
    "At a high level, the idea is to divide the sample into three subsets (not necessarily of equal size). The `splitting` subset is used to fit a decision tree whose objective is modified to maximize heterogeneity in treatment effect estimates across leaves. The `estimation` subset is then used to produce a valid estimate of the treatment effect at each leaf of the fitted tree. Finally, a `test` subset can be used to validate the tree estimates.\n",
    "\n",
    "The next snippet uses `honest.causalTree` function from the [`causalTree`](https://github.com/susanathey/causalTree) package. For more details, see the [causalTree documentation](https://github.com/susanathey/causalTree/blob/master/briefintro.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7ae6324c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>age</th>\n",
       "      <th>polviews</th>\n",
       "      <th>income</th>\n",
       "      <th>educ</th>\n",
       "      <th>marital</th>\n",
       "      <th>sex</th>\n",
       "      <th>conservative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28648</th>\n",
       "      <td>36497</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28649</th>\n",
       "      <td>36498</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28650</th>\n",
       "      <td>36499</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28651</th>\n",
       "      <td>36500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28652</th>\n",
       "      <td>36501</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28653 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X  y  w  age  polviews  income  educ  marital  sex  conservative\n",
       "0          1  0  0   28         4      11    14        5    1             0\n",
       "1          2  1  0   54         6      12    16        2    2             0\n",
       "2          3  1  0   44         2      12    16        5    2             1\n",
       "3          6  0  0   47         1       5    10        4    1             1\n",
       "4          7  0  1   19         4       9    10        5    2             0\n",
       "...      ... .. ..  ...       ...     ...   ...      ...  ...           ...\n",
       "28648  36497  0  0   62         5      12    16        1    1             0\n",
       "28649  36498  1  0   66         7       9    12        2    2             0\n",
       "28650  36499  0  1   54         3      11    12        4    2             1\n",
       "28651  36500  0  0   57         3       6    16        3    2             1\n",
       "28652  36501  1  0   30         4      12    14        5    1             0\n",
       "\n",
       "[28653 rows x 10 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ed87e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['age','polviews', 'income','educ','marital','sex']]\n",
    "y = data['y']\n",
    "treatment = data['w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2e043973",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X.columns\n",
    "X = X.values\n",
    "y = y.values\n",
    "treatment = treatment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "d2329ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CL-honest\n",
    "\n",
    "cthl = CausalTree(honest=True, min_size=1, split_size=0.33)\n",
    "cthl.fit(X, y, treatment)\n",
    "cthl.prune()\n",
    "cthl.plot_tree(features=columns, filename=\"bin_tree_honest_1\", show_effect=True, alpha = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "8efaa3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y, train_t, val_t = train_test_split(X, y, treatment, random_state=724, shuffle=True,\n",
    "                                                                          test_size=0.33)\n",
    "# get honest/estimation portion\n",
    "train_x, est_x, train_y, est_y, train_t, est_t = train_test_split(train_x, train_y, train_t, shuffle=True,\n",
    "                                                                          random_state=724, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "37ebe9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9599, 6)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "79efb661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3699006 , -0.3699006 , -0.3699006 , ..., -0.25010086,\n",
       "       -0.3699006 , -0.3699006 ])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cthl_predict = cthl.predict(est_x)\n",
    "cthl_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "c840b418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.66666667, -0.5       , -0.43380279, -0.40642303, -0.40613027,\n",
       "       -0.37373737, -0.3699006 , -0.30637293, -0.25967213, -0.25010086,\n",
       "       -0.20362903, -0.17777778, -0.1375    , -0.08333333,  0.        ])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(cthl_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "636de09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "num_leaves = len(np.unique(cthl_predict))\n",
    "print(num_leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "bc67ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [i for i in range(1,len(np.unique(cthl_predict)) + 1 ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "15d41aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "1c08ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = pd.DataFrame({\"predict\": cthl_predict})\n",
    "predict['leaves'] = pd.Categorical(predict.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "c9135da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict['leaves'] = predict['leaves'].cat.rename_categories(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "2c7f011a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.369901</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.369901</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.369901</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.369901</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.369901</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9594</th>\n",
       "      <td>-0.406130</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9595</th>\n",
       "      <td>-0.433803</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9596</th>\n",
       "      <td>-0.250101</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9597</th>\n",
       "      <td>-0.369901</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9598</th>\n",
       "      <td>-0.369901</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9599 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       predict leaves\n",
       "0    -0.369901      7\n",
       "1    -0.369901      7\n",
       "2    -0.369901      7\n",
       "3    -0.369901      7\n",
       "4    -0.369901      7\n",
       "...        ...    ...\n",
       "9594 -0.406130      5\n",
       "9595 -0.433803      3\n",
       "9596 -0.250101     10\n",
       "9597 -0.369901      7\n",
       "9598 -0.369901      7\n",
       "\n",
       "[9599 rows x 2 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
